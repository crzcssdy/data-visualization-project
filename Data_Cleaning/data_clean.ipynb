{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pycountry\n",
    "import json\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def extract_numeric_year(column_name):\n",
    "  match = re.match(r'(\\d+) \\[YR(\\d+)\\]', column_name)\n",
    "  if match:\n",
    "    return match.group(1)\n",
    "  else:\n",
    "    return column_name\n",
    "      \n",
    "# Load the datasets\n",
    "fertility_df = pd.read_csv(\"Resources/Population and Ferility Data by Country.csv\")\n",
    "gdp_df = pd.read_csv(\"Resources/GDP by Country_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to extract numeric year from column names\n",
    "fertility_df.columns = fertility_df.columns.map(extract_numeric_year)\n",
    "gdp_df.columns = gdp_df.columns.map(extract_numeric_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fertility Data Missing Values:\n",
      "Series Name     3\n",
      "Series Code     5\n",
      "Country Name    5\n",
      "Country Code    5\n",
      "1960            5\n",
      "               ..\n",
      "2019            5\n",
      "2020            5\n",
      "2021            5\n",
      "2022            5\n",
      "2023            5\n",
      "Length: 68, dtype: int64\n",
      "\n",
      "GDP Data Missing Values:\n",
      "Country Name    3\n",
      "Country Code    5\n",
      "Series Name     5\n",
      "Series Code     5\n",
      "1960            5\n",
      "               ..\n",
      "2019            5\n",
      "2020            5\n",
      "2021            5\n",
      "2022            5\n",
      "2023            5\n",
      "Length: 68, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values in both datasets\n",
    "fertility_missing = fertility_df.isnull().sum()\n",
    "gdp_missing = gdp_df.isnull().sum()\n",
    "\n",
    "print(\"Fertility Data Missing Values:\")\n",
    "print(fertility_missing)\n",
    "print(\"\\nGDP Data Missing Values:\")\n",
    "print(gdp_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure year columns are integers (Some columns might have extra spaces or different formats)\n",
    "fertility_df.columns = [col.strip() for col in fertility_df.columns]  # Remove any extra spaces\n",
    "gdp_df.columns = [col.strip() for col in gdp_df.columns]  # Remove any extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data (pivot the data so we can have years as columns)\n",
    "fertility_long = pd.melt(fertility_df, id_vars=[\"Series Name\", \"Country Name\", \"Country Code\"], \n",
    "                         var_name=\"Year\", value_name=\"Fertility Rate\")\n",
    "gdp_long = pd.melt(gdp_df, id_vars=[\"Country Name\", \"Country Code\", \"Series Name\", \"Series Code\"], \n",
    "                   var_name=\"Year\", value_name=\"GDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Year column (remove non-integer values)\n",
    "fertility_long['Year'] = pd.to_numeric(fertility_long['Year'], errors='coerce')\n",
    "gdp_long['Year'] = pd.to_numeric(gdp_long['Year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Decimal and Drop NaN values\n",
    "fertility_long.dropna(subset=['Year'], inplace=True)\n",
    "gdp_long.dropna(subset=['Year'], inplace=True)\n",
    "fertility_long['Year'] = fertility_long['Year'].astype(int)\n",
    "gdp_long['Year'] = gdp_long['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the datasets by Country Name, Country Code, and Year\n",
    "merged_df = pd.merge(fertility_long, gdp_long, on=[\"Country Name\", \"Country Code\", \"Year\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the data types are correct (e.g., convert Year to integer, GDP to numeric)\n",
    "merged_df['Year'] = merged_df['Year'].astype(int)\n",
    "merged_df['Fertility Rate'] = pd.to_numeric(merged_df['Fertility Rate'], errors='coerce')\n",
    "merged_df['GDP'] = pd.to_numeric(merged_df['GDP'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with 0\n",
    "merged_df['Fertility Rate'] = merged_df['Fertility Rate'].fillna(0)\n",
    "merged_df['GDP'] = merged_df['GDP'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of valid country names\n",
    "valid_countries = [country.name for country in pycountry.countries]\n",
    "\n",
    "# Filter rows based on country names\n",
    "merged_df = merged_df[merged_df['Country Name'].isin(valid_countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for the years 2014 to 2024\n",
    "filtered_df = merged_df[merged_df['Year'].between(2014, 2024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate countries by keeping only 'GDP per capita (current US$)' rows\n",
    "filtered_df = merged_df[merged_df['Series Name_y'] == 'GDP per capita (current US$)'].copy()\n",
    "\n",
    "# Extract the GDP growth values\n",
    "gdp_growth_df = merged_df[merged_df['Series Name_y'] == 'GDP per capita growth (annual %)'][['Country Code', 'GDP']].copy()\n",
    "gdp_growth_df.rename(columns={'GDP': 'GDP Percentage'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowMemoryError",
     "evalue": "malloc of size 376197120 failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m final_dask_df \u001b[38;5;241m=\u001b[39m dask_filtered_df\u001b[38;5;241m.\u001b[39mmerge(dask_gdp_growth_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry Code\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Convert back to pandas DataFrame if needed\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_dask_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask_expr\\_collection.py:476\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[1;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    475\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[1;32m--> 476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\base.py:375\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    352\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 375\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\base.py:661\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 661\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:3723\u001b[0m, in \u001b[0;36mFused._execute_task\u001b[1;34m(graph, name, *deps)\u001b[0m\n\u001b[0;32m   3721\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(deps):\n\u001b[0;32m   3722\u001b[0m     graph[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;241m=\u001b[39m dep\n\u001b[1;32m-> 3723\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\dataframe\\multi.py:298\u001b[0m, in \u001b[0;36mmerge_chunk\u001b[1;34m(lhs, result_meta, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m             kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 298\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mlhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;66;03m# Workaround for pandas bug where if the left frame of a merge operation is\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# empty, the resulting dataframe can have columns in the wrong order.\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# https://github.com/pandas-dev/pandas/issues/9937\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lhs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\table.pxi:1043\u001b[0m, in \u001b[0;36mpyarrow.lib.ChunkedArray.take\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\compute.py:486\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(data, indices, boundscheck, memory_pool)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03mSelect values (or records) from array- or table-like data given integer\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;124;03mselection indices.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m]\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    485\u001b[0m options \u001b[38;5;241m=\u001b[39m TakeOptions(boundscheck\u001b[38;5;241m=\u001b[39mboundscheck)\n\u001b[1;32m--> 486\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtake\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_pool\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\_compute.pyx:590\u001b[0m, in \u001b[0;36mpyarrow._compute.call_function\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\_compute.pyx:385\u001b[0m, in \u001b[0;36mpyarrow._compute.Function.call\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowMemoryError\u001b[0m: malloc of size 376197120 failed"
     ]
    }
   ],
   "source": [
    "# Merge the GDP Percentage data with the filtered DataFrame\n",
    "final_df = filtered_df.merge(gdp_growth_df, on='Country Code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered data to a CSV and JSONfile\n",
    "filtered_df.to_csv('Resources/filtered_population_fertility_gdp_2014_2024.csv', index=False)\n",
    "filtered_df.to_json('Resources/filtered_population_fertility_gdp_2014_2024.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first few rows of the filtered data to verify\n",
    "filtered_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
